// Chapter content for Bayesian Networks course
// Each chapter has its content in markdown format

export const bayesianChapters = {
    '01-introduction': `
# Module 1 : Introduction aux R√©seaux Bay√©siens

## Qu'est-ce qu'un R√©seau Bay√©sien ?

Un **R√©seau Bay√©sien** (RB) est un mod√®le graphique probabiliste qui repr√©sente un ensemble de variables al√©atoires et leurs **d√©pendances conditionnelles** via un graphe orient√© acyclique (DAG).

### Pourquoi les utiliser ?

| Avantage | Description |
|----------|-------------|
| üéØ **Mod√©lisation causale** | Repr√©sente les relations cause-effet |
| üîç **Raisonnement bidirectionnel** | Diagnostic ET pr√©diction |
| üìä **Gestion de l'incertitude** | Probabilit√©s plut√¥t que certitudes |
| üß© **Interpr√©tabilit√©** | Structure explicite et compr√©hensible |

### Applications concr√®tes

- **M√©decine** : Diagnostic m√©dical (ex: aide au diagnostic COVID)
- **Finance** : √âvaluation des risques de cr√©dit
- **Industrie** : Maintenance pr√©dictive
- **Marketing** : Segmentation client, propension √† l'achat

## Historique

- **1988** : Judea Pearl formalise les r√©seaux bay√©siens
- **1990s** : D√©veloppement des algorithmes d'inf√©rence efficaces
- **2000s** : Applications industrielles massives
- **2011** : Prix Turing pour Judea Pearl

## Exemple introductif : Le r√©seau "Alarme"

Imaginons un syst√®me d'alarme domestique :
- L'alarme peut se d√©clencher suite √† un **cambriolage** OU un **tremblement de terre**
- Si l'alarme sonne, **Jean** et **Marie** (voisins) peuvent appeler

\`\`\`
    Cambriolage     Tremblement
         \\           /
          ‚Üò         ‚Üô
            Alarme
           /       \\
          ‚Üì         ‚Üì
       Jean       Marie
      appelle    appelle
\`\`\`

### Questions que le RB peut r√©soudre :

1. **Pr√©diction** : Si un cambriolage se produit, quelle est la probabilit√© que Jean appelle ?
2. **Diagnostic** : Si Jean appelle, quelle est la probabilit√© qu'il y ait eu un cambriolage ?
3. **Explaining away** : Si Jean appelle ET qu'il y a un tremblement, la probabilit√© de cambriolage diminue !

## Composants d'un R√©seau Bay√©sien

### 1. Structure (Graphe)
- **N≈ìuds** = Variables al√©atoires
- **Ar√™tes** = D√©pendances directes (Parent ‚Üí Enfant)
- **DAG** = Directed Acyclic Graph (pas de cycles)

### 2. Param√®tres (CPT)
- Chaque n≈ìud a une **Table de Probabilit√© Conditionnelle** (CPT)
- P(N≈ìud | Parents) pour les n≈ìuds avec parents
- P(N≈ìud) pour les n≈ìuds racines

## Installation de pgmpy

\`\`\`python
# Installation
pip install pgmpy

# Imports de base
from pgmpy.models import BayesianNetwork
from pgmpy.factors.discrete import TabularCPD
from pgmpy.inference import VariableElimination
\`\`\`

## Exercice üéØ

**R√©flexion** : Pensez √† un probl√®me de votre domaine qui pourrait √™tre mod√©lis√© par un r√©seau bay√©sien. Identifiez :
1. Les variables importantes
2. Les relations de d√©pendance entre elles
3. Quelles questions d'inf√©rence vous aimeriez poser
`,

    '02-probabilites': `
# Module 2 : Rappels de Probabilit√©s

## Probabilit√©s de Base

### D√©finitions fondamentales

| Concept | D√©finition | Notation |
|---------|------------|----------|
| **Probabilit√© marginale** | P d'un √©v√©nement seul | P(A) |
| **Probabilit√© jointe** | P de plusieurs √©v√©nements ensemble | P(A, B) |
| **Probabilit√© conditionnelle** | P d'un √©v√©nement sachant un autre | P(A | B) |

### R√®gle de Bayes

La formule fondamentale qui permet d'inverser les conditionnelles :

\`\`\`
P(A | B) = P(B | A) √ó P(A) / P(B)
\`\`\`

- **P(A | B)** : Posterior (ce qu'on cherche)
- **P(B | A)** : Vraisemblance (likelihood)
- **P(A)** : Prior (croyance a priori)
- **P(B)** : Evidence (normalisation)

### Exemple concret

> Si 1% de la population a une maladie, et un test d√©tecte 90% des malades (sensibilit√©) mais donne 5% de faux positifs...
> **Quelle est la probabilit√© d'√™tre malade si le test est positif ?**

\`\`\`python
# Donn√©es
P_maladie = 0.01  # Prior
P_positif_si_malade = 0.90  # Sensibilit√©
P_positif_si_sain = 0.05  # Faux positifs

# Calcul de P(positif) - loi totale
P_positif = P_positif_si_malade * P_maladie + P_positif_si_sain * (1 - P_maladie)

# Bayes
P_malade_si_positif = (P_positif_si_malade * P_maladie) / P_positif
print(f"P(malade | positif) = {P_malade_si_positif:.2%}")
# R√©sultat : environ 15% ! (bien plus bas qu'attendu)
\`\`\`

## Ind√©pendance

### Ind√©pendance marginale

Deux variables A et B sont **ind√©pendantes** si :

\`\`\`
P(A, B) = P(A) √ó P(B)
\`\`\`

ou de fa√ßon √©quivalente :

\`\`\`
P(A | B) = P(A)
\`\`\`

### Ind√©pendance conditionnelle

A et B sont **conditionnellement ind√©pendantes** sachant C si :

\`\`\`
P(A, B | C) = P(A | C) √ó P(B | C)
\`\`\`

> üí° C'est le concept **cl√©** des r√©seaux bay√©siens !

## R√®gle de la cha√Æne (Chain Rule)

Pour calculer une probabilit√© jointe :

\`\`\`
P(A, B, C) = P(A) √ó P(B | A) √ó P(C | A, B)
\`\`\`

Plus g√©n√©ralement pour n variables :

\`\`\`
P(X‚ÇÅ, X‚ÇÇ, ..., X‚Çô) = ‚àè P(X·µ¢ | X‚ÇÅ, ..., X·µ¢‚Çã‚ÇÅ)
\`\`\`

### Simplification gr√¢ce aux RB

Dans un r√©seau bay√©sien, gr√¢ce aux ind√©pendances conditionnelles :

\`\`\`
P(X‚ÇÅ, ..., X‚Çô) = ‚àè P(X·µ¢ | Parents(X·µ¢))
\`\`\`

C'est beaucoup plus simple ! Au lieu de conditionner sur TOUTES les variables pr√©c√©dentes, on conditionne uniquement sur les **parents directs**.

## Exercice üéØ

Calculez P(Alarme = Oui) dans le r√©seau suivant :
- P(Cambriolage) = 0.001
- P(Tremblement) = 0.002
- P(Alarme | Camb=O, Trem=O) = 0.95
- P(Alarme | Camb=O, Trem=N) = 0.94
- P(Alarme | Camb=N, Trem=O) = 0.29
- P(Alarme | Camb=N, Trem=N) = 0.001
`,

    '03-independance': `
# Module 3 : Ind√©pendance Conditionnelle et d-S√©paration

## Pourquoi l'ind√©pendance conditionnelle ?

L'ind√©pendance conditionnelle est le **fondement th√©orique** des r√©seaux bay√©siens. Elle permet de :
1. **Simplifier** les calculs de probabilit√©s
2. **R√©duire** le nombre de param√®tres √† estimer
3. **Encoder** les connaissances causales

## Les 3 Structures de Base

### 1. Cha√Æne (Chain)

\`\`\`
A ‚Üí B ‚Üí C
\`\`\`

- **A et C sont-ils ind√©pendants ?** Non, A influence C via B
- **A et C sont-ils ind√©pendants sachant B ?** OUI !

> Si on conna√Æt B, A n'apporte plus d'information sur C.

**Exemple** : Fumer ‚Üí Cancer ‚Üí Toux
- Si on sait qu'il y a un cancer, savoir si la personne fume n'aide pas √† pr√©dire la toux.

### 2. Cause Commune (Fork / Common Cause)

\`\`\`
A ‚Üê B ‚Üí C
\`\`\`

- **A et C ind√©pendants ?** Non, ils ont une cause commune B
- **A et C ind√©pendants sachant B ?** OUI !

> Observer B "bloque" la corr√©lation entre A et C.

**Exemple** : Temp√©rature ‚Üí Glace + Temp√©rature ‚Üí Noyades
- Glaces et noyades sont corr√©l√©es (√©t√©), mais sachant la temp√©rature, ils deviennent ind√©pendants.

### 3. V-Structure (Collider / Explaining Away)

\`\`\`
A ‚Üí B ‚Üê C
\`\`\`

- **A et C ind√©pendants ?** OUI ! (pas de lien direct)
- **A et C ind√©pendants sachant B ?** NON !

> C'est contre-intuitif : observer B **cr√©e** une d√©pendance entre A et C !

**Exemple** : Cambriolage ‚Üí Alarme ‚Üê Tremblement
- Cambriolage et Tremblement sont ind√©pendants a priori
- Mais si l'alarme sonne, et qu'on sait qu'il y a un tremblement, √ßa "explique" l'alarme et **r√©duit** la probabilit√© de cambriolage !

## D-S√©paration

La **d-s√©paration** est l'algorithme qui d√©termine si deux variables sont conditionnellement ind√©pendantes dans un DAG.

### R√®gles

Deux n≈ìuds X et Y sont **d-s√©par√©s** par un ensemble Z si TOUT chemin entre X et Y est "bloqu√©".

Un chemin est bloqu√© si :
1. Il contient une **cha√Æne** A ‚Üí B ‚Üí C ou **fork** A ‚Üê B ‚Üí C o√π B ‚àà Z
2. Il contient un **collider** A ‚Üí B ‚Üê C o√π B ‚àâ Z et aucun descendant de B n'est dans Z

### Exemple avec pgmpy

\`\`\`python
from pgmpy.models import BayesianNetwork

model = BayesianNetwork([
    ('Cambriolage', 'Alarme'),
    ('Tremblement', 'Alarme'),
    ('Alarme', 'JeanAppelle'),
    ('Alarme', 'MarieAppelle')
])

# Cambriolage ‚ä• Tremblement ? (sans observation)
print(model.is_d_separated('Cambriolage', 'Tremblement', {}))
# True : marginalement ind√©pendants

# Cambriolage ‚ä• Tremblement | Alarme ?
print(model.is_d_separated('Cambriolage', 'Tremblement', {'Alarme'}))
# False : conditionnellement d√©pendants (explaining away)

# JeanAppelle ‚ä• MarieAppelle | Alarme ?
print(model.is_d_separated('JeanAppelle', 'MarieAppelle', {'Alarme'}))
# True : conditionnellement ind√©pendants
\`\`\`

## Markov Blanket

Le **Markov Blanket** d'un n≈ìud X est l'ensemble minimal de n≈ìuds qui rend X ind√©pendant de tous les autres.

\`\`\`
Markov Blanket(X) = Parents(X) ‚à™ Enfants(X) ‚à™ Co-Parents(X)
\`\`\`

> Connaissant le Markov Blanket, on peut ignorer tout le reste du r√©seau pour X !

## Exercice üéØ

Dans le r√©seau :
\`\`\`
A ‚Üí B ‚Üí D
      ‚Üë
C ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
\`\`\`

1. A et C sont-ils d-s√©par√©s par {} ?
2. A et C sont-ils d-s√©par√©s par {B} ?
3. A et D sont-ils d-s√©par√©s par {B} ?
`,

    '04-dag': `
# Module 4 : Graphes Orient√©s Acycliques (DAG)

## D√©finition formelle

Un **DAG** (Directed Acyclic Graph) est un graphe o√π :
- Les ar√™tes sont **orient√©es** (fl√®ches)
- Il n'existe **aucun cycle** (impossible de revenir √† un n≈ìud en suivant les fl√®ches)

### Terminologie

| Terme | D√©finition |
|-------|------------|
| **Parent** | N≈ìud avec une fl√®che vers X |
| **Enfant** | N≈ìud vers lequel X a une fl√®che |
| **Anc√™tre** | Parent, ou parent de parent, etc. |
| **Descendant** | Enfant, ou enfant d'enfant, etc. |
| **Racine** | N≈ìud sans parent |
| **Feuille** | N≈ìud sans enfant |

## Construction d'un DAG avec pgmpy

\`\`\`python
from pgmpy.models import BayesianNetwork

# D√©finir les ar√™tes : liste de tuples (parent, enfant)
model = BayesianNetwork([
    ('Pluie', 'Herbe_Mouill√©e'),
    ('Arroseur', 'Herbe_Mouill√©e'),
    ('Pluie', 'Arroseur')  # La pluie influence l'usage de l'arroseur
])

# Visualiser la structure
print("N≈ìuds:", list(model.nodes()))
print("Ar√™tes:", list(model.edges()))

# Requ√™tes sur la structure
print("Parents de Herbe_Mouill√©e:", model.get_parents('Herbe_Mouill√©e'))
print("Enfants de Pluie:", model.get_children('Pluie'))
\`\`\`

## Visualisation graphique

\`\`\`python
import networkx as nx
import matplotlib.pyplot as plt

# Cr√©er le graphe NetworkX √† partir du mod√®le
G = nx.DiGraph(model.edges())

# Dessiner
pos = nx.spring_layout(G, seed=42)
nx.draw(G, pos, with_labels=True, 
        node_color='lightblue', 
        node_size=2000,
        font_size=10,
        arrows=True,
        arrowsize=20)
plt.title("Structure du R√©seau Bay√©sien")
plt.show()
\`\`\`

## S√©mantique causale

Dans un RB, les ar√™tes repr√©sentent souvent des **relations causales** :
- Parent ‚Üí Enfant signifie "le parent cause (ou influence) l'enfant"

### Attention !
- Corr√©lation ‚â† Causalit√©
- Le DAG encode des **hypoth√®ses** causales
- Ces hypoth√®ses doivent √™tre valid√©es par des experts du domaine

## Propri√©t√©s importantes

### Ordre topologique

Un DAG peut toujours √™tre ordonn√© de fa√ßon **topologique** :
Chaque n≈ìud appara√Æt apr√®s tous ses parents.

\`\`\`python
import networkx as nx

# Obtenir un ordre topologique
order = list(nx.topological_sort(G))
print("Ordre topologique:", order)
# Ex: ['Pluie', 'Arroseur', 'Herbe_Mouill√©e']
\`\`\`

### Factorisation

Le DAG d√©finit une **factorisation** de la distribution jointe :

\`\`\`
P(X‚ÇÅ, ..., X‚Çô) = ‚àè P(X·µ¢ | Parents(X·µ¢))
\`\`\`

## Bonnes pratiques de mod√©lisation

1. **Commencez par les causes** (n≈ìuds racines)
2. **√âvitez les cycles** (physiquement impossibles dans un DAG)
3. **Validez avec des experts** du domaine
4. **Testez les ind√©pendances** implicites du mod√®le

## Exercice üéØ

Mod√©lisez le sc√©nario suivant en DAG :
- Le niveau d'√©tudes influence le salaire
- Le salaire influence le quartier de r√©sidence
- Le quartier influence la qualit√© de l'√©cole des enfants
- Le niveau d'√©tudes des parents influence aussi directement les r√©sultats scolaires des enfants
`,

    '05-cpt': `
# Module 5 : Tables de Probabilit√©s Conditionnelles (CPT)

## D√©finition

Une **CPT** (Conditional Probability Table) d√©finit la distribution de probabilit√© d'un n≈ìud **√©tant donn√© ses parents**.

- Pour un n≈ìud **racine** : P(X) - distribution marginale
- Pour un n≈ìud avec **parents** : P(X | Parents)

## Structure d'une CPT

### N≈ìud sans parent

\`\`\`python
from pgmpy.factors.discrete import TabularCPD

# P(Pluie) - 2 √©tats : [Non, Oui]
cpd_pluie = TabularCPD(
    variable='Pluie',
    variable_card=2,  # Nombre d'√©tats
    values=[[0.8], [0.2]]  # P(Non)=0.8, P(Oui)=0.2
)
print(cpd_pluie)
\`\`\`

Sortie :
\`\`\`
+----------+-----+
| Pluie(0) | 0.8 |
+----------+-----+
| Pluie(1) | 0.2 |
+----------+-----+
\`\`\`

### N≈ìud avec un parent

\`\`\`python
# P(Herbe_Mouill√©e | Pluie)
cpd_herbe = TabularCPD(
    variable='Herbe_Mouill√©e',
    variable_card=2,
    values=[
        [0.9, 0.1],  # P(Sec | Pluie=Non), P(Sec | Pluie=Oui)
        [0.1, 0.9]   # P(Mouill√© | ...)
    ],
    evidence=['Pluie'],
    evidence_card=[2]
)
\`\`\`

### N≈ìud avec plusieurs parents

\`\`\`python
# P(Herbe_Mouill√©e | Pluie, Arroseur)
# Les colonnes suivent l'ordre binaire des parents
cpd_herbe = TabularCPD(
    variable='Herbe_Mouill√©e',
    variable_card=2,
    values=[
        # Pluie:       0    0    1    1
        # Arroseur:    0    1    0    1
        [0.95, 0.10, 0.10, 0.01],  # P(Sec | ...)
        [0.05, 0.90, 0.90, 0.99]   # P(Mouill√© | ...)
    ],
    evidence=['Pluie', 'Arroseur'],
    evidence_card=[2, 2]
)
\`\`\`

> ‚ö†Ô∏è **Ordre des colonnes** : L'ordre suit la convention "little-endian". Le premier parent varie le plus lentement.

## Validation du mod√®le

\`\`\`python
# Ajouter toutes les CPT au mod√®le
model.add_cpds(cpd_pluie, cpd_arroseur, cpd_herbe)

# V√©rifier la coh√©rence
if model.check_model():
    print("‚úÖ Mod√®le valide !")
else:
    print("‚ùå Erreur dans le mod√®le")
\`\`\`

## Nombre de param√®tres

Le nombre de param√®tres dans une CPT d√©pend de :
- **|X|** : nombre d'√©tats du n≈ìud
- **|Parents|** : nombre de combinaisons des √©tats des parents

\`\`\`
Param√®tres(CPT) = (|X| - 1) √ó ‚àè|Parent_i|
\`\`\`

### Exemple
- X a 3 √©tats
- 2 parents avec 2 et 4 √©tats

Param√®tres = (3-1) √ó 2 √ó 4 = **16 param√®tres**

## Repr√©sentation alternative : Noisy-OR

Pour √©viter l'explosion des param√®tres avec beaucoup de parents, on peut utiliser des mod√®les param√©triques comme **Noisy-OR**.

\`\`\`python
# Concept : chaque parent cause ind√©pendamment l'effet avec une probabilit√© p_i
# P(Effet=Non | Parents) = ‚àè(1 - p_i) pour chaque parent_i actif
\`\`\`

## Exercice üéØ

Cr√©ez les CPT pour le r√©seau suivant :
- **Fi√®vre** : P(Oui) = 0.05
- **Grippe** : P(Oui | Fi√®vre=Oui) = 0.6, P(Oui | Fi√®vre=Non) = 0.01
- **Fatigue** : d√©pend de Fi√®vre ET Grippe

D√©finissez des valeurs r√©alistes pour P(Fatigue | Fi√®vre, Grippe).
`,

    '06-inference-exacte': `
# Module 6 : Inf√©rence Exacte

## Qu'est-ce que l'inf√©rence ?

L'**inf√©rence** est le calcul de probabilit√©s conditionnelles dans un r√©seau bay√©sien :

\`\`\`
P(Query | Evidence)
\`\`\`

- **Query** : Variables dont on veut la distribution
- **Evidence** : Variables observ√©es (connues)

## Types de requ√™tes

| Type | Question | Exemple |
|------|----------|---------|
| **Marginale** | P(X) | Probabilit√© a priori d'un cambriolage |
| **Conditionnelle** | P(X \| E) | P(Cambriolage \| Alarme=Oui) |
| **MAP** | argmax P(X \| E) | L'√©tat le plus probable |
| **MPE** | argmax P(X‚ÇÅ,...,X‚Çô \| E) | La configuration compl√®te la plus probable |

## Variable Elimination

L'algorithme **Variable Elimination** calcule P(Q | E) de mani√®re exacte.

### Principe
1. Fixer les variables observ√©es
2. √âliminer les variables cach√©es une par une
3. Multiplier les facteurs et marginaliser

### Impl√©mentation avec pgmpy

\`\`\`python
from pgmpy.inference import VariableElimination

# Cr√©er l'objet d'inf√©rence
infer = VariableElimination(model)

# Query simple : P(Cambriolage | JeanAppelle=Oui)
result = infer.query(
    variables=['Cambriolage'],
    evidence={'JeanAppelle': 1}
)
print(result)
\`\`\`

### Query avec plusieurs variables

\`\`\`python
# P(Cambriolage, Tremblement | Alarme=Oui)
result = infer.query(
    variables=['Cambriolage', 'Tremblement'],
    evidence={'Alarme': 1}
)
print(result)
\`\`\`

## MAP Query (Maximum A Posteriori)

Trouve l'√©tat le plus probable des variables query.

\`\`\`python
# Quel est l'√©tat le plus probable ?
map_result = infer.map_query(
    variables=['Cambriolage', 'Tremblement'],
    evidence={'JeanAppelle': 1, 'MarieAppelle': 1}
)
print("√âtat le plus probable:", map_result)
# {'Cambriolage': 1, 'Tremblement': 0}
\`\`\`

## Complexit√©

La complexit√© de Variable Elimination d√©pend de la **treewidth** du graphe.

| Treewidth | Complexit√© | Praticable ? |
|-----------|------------|--------------|
| Petit (< 15) | O(n √ó d^w) | ‚úÖ Rapide |
| Grand (> 30) | Exponentiel | ‚ùå Impraticable |

> Pour les grands r√©seaux, on utilise l'inf√©rence approch√©e (Module 7).

## Belief Propagation

Pour les **arbres** (graphes sans cycles), l'algorithme **Belief Propagation** est optimal.

\`\`\`python
from pgmpy.inference import BeliefPropagation

bp = BeliefPropagation(model)
bp.calibrate()  # Pr√©-calcul des messages

result = bp.query(['Cambriolage'], evidence={'JeanAppelle': 1})
\`\`\`

## Exercice üéØ

Dans le r√©seau Alarme :
1. Calculez P(Cambriolage | Alarme=Oui)
2. Calculez P(Cambriolage | JeanAppelle=Oui, MarieAppelle=Oui)
3. Comparez les r√©sultats et expliquez la diff√©rence
`,

    '07-inference-approchee': `
# Module 7 : Inf√©rence Approch√©e (Sampling)

## Pourquoi l'inf√©rence approch√©e ?

L'inf√©rence exacte devient **impraticable** pour :
- Les r√©seaux tr√®s grands
- Les r√©seaux avec beaucoup de connexions (treewidth √©lev√©e)

L'inf√©rence approch√©e utilise des **√©chantillons** pour estimer les probabilit√©s.

## Forward Sampling

G√©n√®re des √©chantillons selon la distribution jointe du mod√®le.

\`\`\`python
from pgmpy.sampling import BayesianModelSampling

sampler = BayesianModelSampling(model)

# G√©n√©rer 1000 √©chantillons
samples = sampler.forward_sample(size=1000)
print(samples.head())
\`\`\`

### Estimer des probabilit√©s

\`\`\`python
# Estimer P(Alarme=1)
p_alarme = samples['Alarme'].mean()
print(f"P(Alarme) ‚âà {p_alarme:.4f}")

# Estimer P(Cambriolage=1, Alarme=1)
p_joint = ((samples['Cambriolage'] == 1) & (samples['Alarme'] == 1)).mean()
print(f"P(Cambriolage, Alarme) ‚âà {p_joint:.4f}")
\`\`\`

## Rejection Sampling

Pour estimer P(Q | E), on g√©n√®re des √©chantillons et on **rejette** ceux incompatibles avec E.

\`\`\`python
# P(Cambriolage | JeanAppelle=1)
samples_given = sampler.rejection_sample(
    size=1000,
    evidence=[('JeanAppelle', 1)]
)

p_camb_given = samples_given['Cambriolage'].mean()
print(f"P(Cambriolage | JeanAppelle) ‚âà {p_camb_given:.4f}")
\`\`\`

### ‚ö†Ô∏è Probl√®me du Rejection Sampling

Si l'√©vidence est **rare**, presque tous les √©chantillons sont rejet√©s !

Exemple : Si P(JeanAppelle=1) = 0.01, il faudrait g√©n√©rer ~100 √©chantillons pour en garder 1.

## Likelihood Weighting

Solution au probl√®me de rejet : on **force** l'√©vidence et on **pond√®re** les √©chantillons.

\`\`\`python
samples_weighted = sampler.likelihood_weighted_sample(
    size=1000,
    evidence=[('JeanAppelle', 1)]
)

# Les √©chantillons ont un poids proportionnel √† P(evidence | parents)
print(samples_weighted[['Cambriolage', '_weight']].head(10))
\`\`\`

## Gibbs Sampling (MCMC)

M√©thode it√©rative qui explore l'espace des √©tats.

\`\`\`python
from pgmpy.sampling import GibbsSampling

gibbs = GibbsSampling(model)
samples = gibbs.sample(size=1000)
\`\`\`

### Principe
1. Initialiser toutes les variables
2. Pour chaque variable (sauf evidence) :
   - √âchantillonner selon P(X | Markov_Blanket(X))
3. R√©p√©ter

### Burn-in

Les premiers √©chantillons sont biais√©s par l'initialisation. On les ignore.

\`\`\`python
samples = gibbs.sample(size=1000)
samples_clean = samples.iloc[200:]  # Ignorer les 200 premiers (burn-in)
\`\`\`

## Comparaison des m√©thodes

| M√©thode | Avantages | Inconv√©nients |
|---------|-----------|---------------|
| **Forward** | Simple, rapide | Pas de conditionnement |
| **Rejection** | Simple | Inefficace si √©vidence rare |
| **Likelihood** | √âvite le rejet | Variance peut √™tre √©lev√©e |
| **Gibbs** | Efficace, flexible | Convergence lente possible |

## Exercice üéØ

1. Utilisez Forward Sampling pour estimer P(Alarme)
2. Utilisez Rejection Sampling pour estimer P(Cambriolage | Alarme=1)
3. Comparez avec les valeurs exactes (Variable Elimination)
`,

    '08-apprentissage-params': `
# Module 8 : Apprentissage des Param√®tres

## Contexte

On conna√Æt la **structure** (le DAG) mais pas les **param√®tres** (CPT).
On veut les **estimer √† partir de donn√©es**.

## Maximum Likelihood Estimation (MLE)

Le MLE estime les param√®tres en **comptant les fr√©quences** dans les donn√©es.

\`\`\`python
import pandas as pd
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

# Donn√©es d'entra√Ænement
data = pd.DataFrame({
    'Pluie':    [1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0],
    'Arroseur': [0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1],
    'Mouill√©':  [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]
})

# D√©finir la structure
model = BayesianNetwork([
    ('Pluie', 'Mouill√©'),
    ('Arroseur', 'Mouill√©')
])

# Estimer les param√®tres par MLE
model.fit(data, estimator=MaximumLikelihoodEstimator)

# Afficher les CPT apprises
for cpd in model.get_cpds():
    print(f"\\n=== {cpd.variable} ===")
    print(cpd)
\`\`\`

### Formule MLE

\`\`\`
P(X=x | Parents=p) = N(X=x, Parents=p) / N(Parents=p)
\`\`\`

## Probl√®me : Donn√©es manquantes

Si certaines combinaisons n'apparaissent pas dans les donn√©es, le MLE donne P=0 !

\`\`\`python
# Exemple : aucun cas o√π Pluie=1 et Arroseur=1
# ‚Üí P(Mouill√© | Pluie=1, Arroseur=1) = ind√©fini !
\`\`\`

## Bayesian Estimation

Solution : ajouter des **pseudo-observations** (prior).

\`\`\`python
from pgmpy.estimators import BayesianEstimator

model_bayes = BayesianNetwork([
    ('Pluie', 'Mouill√©'),
    ('Arroseur', 'Mouill√©')
])

model_bayes.fit(
    data,
    estimator=BayesianEstimator,
    prior_type='BDeu',  # Prior uniforme
    equivalent_sample_size=5  # Force du prior
)

print(model_bayes.get_cpds('Mouill√©'))
\`\`\`

### Types de priors

| Prior | Description |
|-------|-------------|
| **BDeu** | Bayesian Dirichlet equivalent uniform |
| **K2** | Prior non-informatif |
| **Dirichlet** | Prior personnalis√© |

### Effet du prior

\`\`\`
P(X=x | Parents=p) = (N(X=x, p) + Œ±) / (N(p) + Œ± √ó |X|)
\`\`\`

- **Œ±** petit : Donn√©es dominent (proche MLE)
- **Œ±** grand : Prior domine (lissage fort)

## Donn√©es incompl√®tes (Missing Data)

Si certaines valeurs sont manquantes (NaN), on utilise l'algorithme **EM** (Expectation-Maximization).

\`\`\`python
from pgmpy.estimators import ExpectationMaximization

# Donn√©es avec valeurs manquantes
data_missing = data.copy()
data_missing.loc[0, 'Pluie'] = None
data_missing.loc[3, 'Mouill√©'] = None

em = ExpectationMaximization(model, data_missing)
model_em = em.get_parameters()
\`\`\`

## Validation

Apr√®s l'apprentissage, validez sur des donn√©es de test.

\`\`\`python
from sklearn.model_selection import train_test_split

train, test = train_test_split(data, test_size=0.2)

model.fit(train, estimator=MaximumLikelihoodEstimator)

# √âvaluer la log-vraisemblance sur le test
# (m√©triques sp√©cifiques aux RB)
\`\`\`

## Exercice üéØ

1. Cr√©ez un dataset de 100 √©chantillons pour le r√©seau Pluie/Arroseur/Mouill√©
2. Apprenez les param√®tres par MLE
3. Comparez avec les "vraies" probabilit√©s utilis√©es pour g√©n√©rer les donn√©es
`,

    '09-apprentissage-structure': `
# Module 9 : Apprentissage de Structure

## Contexte

On ne conna√Æt **ni la structure ni les param√®tres**.
On veut d√©couvrir le DAG optimal √† partir des donn√©es.

## Approches

### 1. Score-based (Recherche)

Explore l'espace des DAGs possibles et cherche celui avec le meilleur **score**.

### 2. Constraint-based (Tests)

Utilise des **tests d'ind√©pendance** statistiques pour d√©couvrir les ar√™tes.

## Hill Climbing (Score-based)

Algorithme glouton qui am√©liore it√©rativement le DAG.

\`\`\`python
import pandas as pd
from pgmpy.estimators import HillClimbSearch, BicScore

# Donn√©es
data = pd.DataFrame({
    'A': [0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0],
    'B': [0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1],
    'C': [0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]
})

# Hill Climbing avec score BIC
hc = HillClimbSearch(data)
best_dag = hc.estimate(scoring_method=BicScore(data))

print("Structure d√©couverte:")
print("Ar√™tes:", list(best_dag.edges()))
\`\`\`

### Op√©rations de modification

1. **Ajouter** une ar√™te
2. **Supprimer** une ar√™te
3. **Inverser** une ar√™te

√Ä chaque √©tape, on choisit l'op√©ration qui **am√©liore le score**.

## Scores

| Score | Description |
|-------|-------------|
| **BIC** | Bayesian Information Criterion (p√©nalise la complexit√©) |
| **K2** | Score de Cooper & Herskovits |
| **BDeu** | Bayesian Dirichlet equivalent uniform |

\`\`\`python
from pgmpy.estimators import K2Score

# Comparer les scores
bic = BicScore(data)
k2 = K2Score(data)

print("Score BIC:", bic.score(best_dag))
print("Score K2:", k2.score(best_dag))
\`\`\`

## PC Algorithm (Constraint-based)

D√©couvre les ar√™tes via des tests d'ind√©pendance conditionnelle.

\`\`\`python
from pgmpy.estimators import PC

pc = PC(data)
model = pc.estimate(
    significance_level=0.05,  # Niveau de confiance
    variant='stable'
)

print("Structure (PC):", list(model.edges()))
\`\`\`

### √âtapes du PC
1. Commencer avec un graphe **complet** (toutes les ar√™tes)
2. Pour chaque paire, tester l'ind√©pendance marginale
3. Pour chaque paire, tester l'ind√©pendance conditionnelle
4. Orienter les ar√™tes (r√®gles de v-structures)

## Combinaison : MMHC

**Max-Min Hill Climbing** combine les deux approches :
1. PC pour identifier les ar√™tes candidates
2. Hill Climbing pour l'optimisation finale

\`\`\`python
from pgmpy.estimators import MmhcEstimator

mmhc = MmhcEstimator(data)
model = mmhc.estimate()
print("Structure (MMHC):", list(model.edges()))
\`\`\`

## Construire le mod√®le complet

\`\`\`python
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator

# 1. Apprendre la structure
hc = HillClimbSearch(data)
best_dag = hc.estimate(scoring_method=BicScore(data))

# 2. Cr√©er le mod√®le
model = BayesianNetwork(best_dag.edges())

# 3. Apprendre les param√®tres
model.fit(data, estimator=MaximumLikelihoodEstimator)

# 4. Utiliser le mod√®le
from pgmpy.inference import VariableElimination
infer = VariableElimination(model)
result = infer.query(['C'], evidence={'A': 1})
print(result)
\`\`\`

## √âvaluation

### Metrics structurelles

\`\`\`python
# Comparer avec le vrai DAG (si connu)
true_edges = {('A', 'B'), ('B', 'C')}
learned_edges = set(best_dag.edges())

TP = len(true_edges & learned_edges)  # Vrais positifs
FP = len(learned_edges - true_edges)  # Faux positifs
FN = len(true_edges - learned_edges)  # Faux n√©gatifs

precision = TP / (TP + FP) if (TP + FP) > 0 else 0
recall = TP / (TP + FN) if (TP + FN) > 0 else 0
print(f"Pr√©cision: {precision:.2%}, Rappel: {recall:.2%}")
\`\`\`

## Exercice üéØ

1. G√©n√©rez des donn√©es √† partir d'un RB connu (A ‚Üí B ‚Üí C)
2. Utilisez Hill Climbing pour retrouver la structure
3. Comparez la structure apprise avec la vraie
`
};

export const getChapterContent = (chapterId) => {
    return bayesianChapters[chapterId] || null;
};
